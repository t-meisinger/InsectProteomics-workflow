#######################################################################################################################################################
# Proteomic insights into Novel Food Insects: Homology-based proteome characterization and allergenicity considerations for EU-regulated insect species 
# Tobias Meisinger, Hannes Planatscher, Albert Braeuning, Eva-Maria Ladenburger, Dieter Stoll, Cristiano Garino, Hermann Broll, Oliver Poetz
# 2025

# Script to sort and filter peptide results derived from DDA experiments, that were identified using MASCOT. 
# See section "DDA protein results filtering" of the manuscript.
# This script exports a CSV file containing all filtered and cleaned results.
# This script can be run in batch mode or on a single file.

# Instructions: 1. Install all required packages, as defined in the import section
#               2. Save species-specific MASCOT export CSV files and this script in the same directory.
#               3. Run from CMD (Windows) or bash (Linux): 
#                   python MASCOT-csv_clean.py
#######################################################################################################################################################

# Imports
import os
import glob
import pandas as pd
import argparse
import re

# Commandline parameters
parser = argparse.ArgumentParser(description='This script cleans and filters peptide data from CSV files generated by Mascot, ensuring uniformity in columns like emPAI and emPAI_value, and outputs cleaned results to new CSV files while removing temporary processing files. CAVE: If no specific file is given, all CSV files in the working directory will be processed!')
parser.add_argument('-o', '--open', action='store', dest='openFile', default=None, required=False, help='Specify CSV file to open.')
args = parser.parse_args()
openFile = args.openFile

# Function to clean a single CSV file
def clean_csv(file):
    try:
        # Read the file line by line to find the start of the relevant dataset
        with open(file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # Identify the start of the relevant dataset
        start = None
        end = None
        for i, line in enumerate(lines):
            if 'prot_hit_num' in line:
                start = i
                break
        
        # Identify the end of the relevant dataset
        for i in range(start, len(lines)):
            if 'Peptide matches not assigned to protein hits' in lines[i]:
                end = i
                break

        if start is None or end is None:
            raise ValueError("Required markers not found in the file. Relevant dataset cannot be determined by this script.")

        # Extract the relevant dataset and add column headers for empAI and emPAI_values
        relevant_lines = lines[start:end]
        relevant_lines[0] = relevant_lines[0].strip() + ',emPAI,protein_emPAI_value\n'

        # Write the relevant dataset to a temporary CSV file
        temp_file = 'temp.csv'
        with open(temp_file, 'w', encoding='utf-8') as f:
            f.writelines(relevant_lines)
            
        # Load the temporary CSV file with proper header handling
        df = pd.read_csv(temp_file, header=0, low_memory=False, on_bad_lines='warn')
        
        if 'prot_desc' in df.columns:
            df[['prot_name', 'uniref_cluster_size', 'taxonomy', 'tax_id', 'rep_id']] = df['prot_desc'].str.extract(r'(.*?)\sn=(\d+)\sTax=(.*?)\sTaxID=(\d+)\sRepID=(.*)')
        
        # emPAI values can only be assigned to proteins and not to peptides. Column emPAI only contains the word "emPAI" and thus is not of help. Drop it.
        df = df.drop(columns='emPAI')
        
        # Fill empty rows in 'protein_emPAI_value' with the nearest non-empty value below: as emPAI values are assigned to proteins, MASCOT writes the value in the row of the last peptide of a protein.
        df['protein_emPAI_value'] = df['protein_emPAI_value'].bfill()
        
        # Drop all rows where pep_isunique == 0 to remove non-unique peptides
        if 'pep_isunique' in df.columns:
            df_pep_isunique = df[df.pep_isunique != 0]
        else:
            df_pep_isunique = df
        
        # Remove duplicate peptides. File contains every query and several subsequent queries show the same peptide. Furthermore, PTMs are listed as individual rows.
        df_no_duplicates = df_pep_isunique.drop_duplicates(subset=['prot_acc', 'pep_seq'], keep='first')
        
        return df_no_duplicates

    except Exception as e:
        print(f"Error processing file {file}: {e}")
        return None

# Main batch processing
def process_files(openFile=None):
    if openFile is not None:
        files = [openFile]
    else:
        files = glob.glob('*.csv')
    
    for file in files:
        saveName = file[:-4] + '_sorted.csv'
        
        # Clean the CSV file
        cleaned_df = clean_csv(file)
        
        if cleaned_df is not None:
            # Save the cleaned DataFrame to a new CSV file
            cleaned_df.to_csv(saveName, sep=',', encoding='utf-8', index=False)
            print(f"Processed and saved: {saveName}")
        else:
            print(f"Failed to process: {file}")
            
        # Remove the temporary CSV file
        if os.path.exists('temp.csv'):
            os.remove('temp.csv')
            print("Temporary file 'temp.csv' removed.")

# Run the processing
if __name__ == "__main__":
    process_files(openFile)
